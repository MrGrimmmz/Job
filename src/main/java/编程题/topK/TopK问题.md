###一亿浮点数，找其中最大的10000个数

- 分治法
    - 将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的10000个，
    最后在剩下的100*10000个数据里面找出最大的10000个。如果100万数据选择足够理想，
    那么可以过滤掉1亿数据里面99%的数据。
    
    - 100万个数据里面查找最大的10000个数据的方法如下：用快速排序的方法，将数据分为2堆，
    如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大的那堆个数N大于10000个，
    继续对大堆快速排序一次分成2堆，如果大堆个数N小于10000个，就在小的那堆里面快速排序一次，找第10000-n大的数字；
    递归以上过程，就可以找到第1w大的数。
    
    - 参考上面的找出第1w大数字，就可以类似的方法找到前10000大数字了。
    此种方法需要每次的内存空间为10^6*4=4MB，一共需要101次这样的比较。
    
- Hash法。
    - 如果这1亿个书里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的10000个数。
    
- 最小堆。
    - 首先读入前10000个数来创建大小为10000的最小堆，建堆的时间复杂度为O（mlogm）（m为数组的大小即为10000），然后遍历后续的数字，并于堆顶（最小）数字进行比较。如果比最小的数小，则继续读取后续数字；如果比堆顶数字大，则替换堆顶元素并重新调整堆为最小堆。整个过程直至1亿个数全部遍历完为止。然后按照中序遍历的方式输出当前堆中的所有10000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是10000（常数）。
    
- 小顶堆（min-heap）有个重要的性质——每个结点的值均不大于其左右孩子结点的值，则堆顶元素即为整个堆的最小值。JDK中PriorityQueue实现了数据结构堆，通过指定comparator字段来表示小顶堆或大顶堆，默认为null，表示自然序（natural ordering）。

- 小顶堆解决Top K问题的思路：小顶堆维护当前扫描到的最大100个数，其后每一次的扫描到的元素，若大于堆顶，则入堆，然后删除堆顶；依此往复，直至扫描完所有元素。Java实现第K大整数代码如下：
```aidl
public int findKthLargest(int[] nums, int k) {
  PriorityQueue<Integer> minQueue = new PriorityQueue<>(k);
  for (int num : nums) {
    if (minQueue.size() < k || num > minQueue.peek())
      minQueue.offer(num);
    if (minQueue.size() > k)
      minQueue.poll();
  }
  return minQueue.peek();
}
```
###hash表
- 哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。
  
  哈希表hashtable(key，value) 的做法其实很简单，就是把Key通过一个固定的算法函数既所谓的哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里。
  
  而当使用哈希表进行查询的时候，就是再次使用哈希函数将key转换为对应的数组下标，并定位到该空间获取value，如此一来，就可以充分利用到数组的定位性能进行数据定位。
  
###统计热门查询

###分治：取100个文件桶，将ip存到hash(ip) % 100的桶里，这样就可以保证同样的ip存在同一个文件里

假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的10个查询串，要求使用的内存不能超过1G。

首先就是要统计每个Query出现的次数，然后根据统计结果，找出Top 10。

- 第一步：Query统计
    - 1、排序法
        - 归并排序
        - 排完序之后我们再对已经有序的Query文件进行遍历，统计每个Query出现的次数，再次写入文件中。
        - 综合分析一下，排序的时间复杂度是O(NlgN)，而遍历的时间复杂度是O(N)，因此该算法的总体时间复杂度就是O(N+NlgN)=O（NlgN）。

    - 2、Hash Table法
        - 维护一个Key为Query字串，Value为该Query出现次数的HashTable，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可。最终我们在O(N)的时间复杂度内完成了对该海量数据的处理。
        - 该方法只需要IO数据文件一次，而算法1的IO次数较多的。
        
- 第二步：找出Top 10
    - 算法一：普通排序
         - 排序算法的时间复杂度是NlgN，在本题目中，三百万条记录，用1G内存是可以存下的。
    
    - 算法二：部分排序
    
        - 题目要求是求出Top 10，因此我们没有必要对所有的Query都进行排序，我们只需要维护一个10个大小的数组，初始化放入10个Query，按照每个Query的统计次数由大到小排序，然后遍历这300万条记录，每读一条记录就和数组最后一个Query对比，如果小于这个Query，那么继续遍历，否则，将数组中最后一条数据淘汰，加入当前的Query。最后当所有的数据都遍历完毕之后，那么这个数组中的10个Query便是我们要找的Top10了。
    
        - 不难分析出，这样，算法的最坏时间复杂度是N*K， 其中K是指top多少。
    
    - 算法三：堆
    
        - 每次查找的时候可以采用二分的方法查找，这样操作的复杂度就降到了logK。能快速查找，又能快速移动元素的数据结构：那就是堆。
        - 借助堆结构，我们可以在log量级的时间内查找和调整/移动。维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比。
        
        - 具体过程是，堆顶存放的是整个堆中最小的数，现在遍历N个数，把最先遍历到的k个数存放到最小堆中，并假设它们就是我们要找的最大的k个数，X1>X2…Xmin(堆顶)，而后遍历后续的N-K个数，一一与堆顶元素进行比较，如果遍历到的Xi大于堆顶元素Xmin，则把Xi放入堆中，而后更新整个堆，更新的时间复杂度为logK，如果Xi < Xmin，则不更新堆，整个过程的复杂度为O(K)+O(（N-K）*logK)=O（N*logK）。
        
   
###字符串出现次数的Top K问题
- 遍历所有N个字符串，建立哈希表，key为字符串，value为字符串的次数；时间复杂度O(N);
- 将哈希表的所有节点逐个加入小根堆，堆调整时间复杂度为O(logk)，根据记录更新小根堆的过程为O(Nlogk)；
- 将堆中k个记录排序输出；时间复杂度为O(klogk)
- 总的时间复杂度为O(N)+O(Nlogk)+O(klogk)，即O(Nlogk)